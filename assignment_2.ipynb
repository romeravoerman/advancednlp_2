{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8769daf0-5f57-434d-bada-904add6276c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870be26c-fc11-433c-860e-bb6873325b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    '''\n",
    "    This function reads the file, pre-processes it, turns it into a pd dataframe and creates .csv\n",
    "    \n",
    "    :param file: the filepath \n",
    "    :type file: string\n",
    "    '''\n",
    "    # read file line by line\n",
    "    with open(file, \"r\") as infile:\n",
    "        content = infile.readlines()\n",
    "    \n",
    "    # delete lines that start with # \n",
    "    content = [x for x in content if not x.startswith('#')]\n",
    "    \n",
    "    # delete empty lines \n",
    "    content = [x for x in content if not x.startswith('\\n')]\n",
    "    \n",
    "    # create dataframe by separating on tab spaces\n",
    "    df = pd.DataFrame([x.split('\\t') for x in content])\n",
    "    \n",
    "    # create headers\n",
    "    headers1 = ['ID','TOKEN','LEMMA','POS-UNIV','POS','MORPH','HEAD','BASIC DEP','ENHANCED DEP','SPACE','PREDICATE']\n",
    "    total_columns = len(df.columns)\n",
    "    headers2 = [*range(0, total_columns-11, 1)]\n",
    "    headers2 = ['LABELS P' + str(x) for x in headers2]\n",
    "    headers_complete = headers1 + headers2\n",
    "    \n",
    "    # add headers to df\n",
    "    df = df.set_axis(headers_complete, axis=1)\n",
    "    \n",
    "    # create csv file\n",
    "    outputfilename = file.replace('.conllu', '.csv')\n",
    "    outputfile = df.to_csv(outputfilename, sep=',')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1be2e74-96aa-47c2-bb66-4987437e4550",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 6770: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_train \u001b[38;5;241m=\u001b[39m \u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_ewt-up-train.conllu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_dev \u001b[38;5;241m=\u001b[39m read_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_ewt-up-dev.conllu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m df_test \u001b[38;5;241m=\u001b[39m read_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_ewt-up-test.conllu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mread_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# read file line by line\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[1;32m---> 10\u001b[0m     content \u001b[38;5;241m=\u001b[39m \u001b[43minfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# delete lines that start with # \u001b[39;00m\n\u001b[0;32m     13\u001b[0m content \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n",
      "File \u001b[1;32mC:\\Program Files\\Python310\\lib\\encodings\\cp1252.py:23\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmap_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdecoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 6770: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "df_train = read_file('en_ewt-up-train.conllu')\n",
    "df_dev = read_file('en_ewt-up-dev.conllu')\n",
    "df_test = read_file('en_ewt-up-test.conllu')\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbda03-14de-4f3a-9001-bdd47a52271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62634-0c10-415b-bd3f-088a5aec4da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee65d355-d20d-4040-a8c7-97c03eccf753",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     outputfile \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_csv(outputfilename, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[1;32m---> 23\u001b[0m additional_features(\u001b[43mdf_train\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men_ewt-up-train.conllu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "def additional_features(df, file):\n",
    "    '''\n",
    "    This function extracts features additional features, adds them to the dataframe \n",
    "    \n",
    "    :param df:\n",
    "    :type df: pandas dataframe\n",
    "    '''\n",
    "    \n",
    "    # previous part-of-speech tag\n",
    "    prev_pos = df['POS'].shift()\n",
    "    df.insert(5, \"PREV POS\", prev_pos)\n",
    "    \n",
    "    # next part-of-speech tag\n",
    "    next_pos = df['POS'].shift(-1)\n",
    "    df.insert(6, \"NEXT POS\", next_pos)\n",
    "    \n",
    "    # create csv file\n",
    "    outputfilename = file.replace('.conllu', '.addfeatures.csv')\n",
    "    outputfile = df.to_csv(outputfilename, sep=',')\n",
    "    \n",
    "    return df\n",
    "\n",
    "additional_features(df_train, 'en_ewt-up-train.conllu')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce5419e-79d1-48ff-b3f9-1a230b68290b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    This function returns the columns with a substring in the column name\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m    :type substring: string\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[:, df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(substring)]\n\u001b[1;32m---> 14\u001b[0m labels \u001b[38;5;241m=\u001b[39m return_columns(\u001b[43mdf_train\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABELS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m labels\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Only return the columns with a substring in the column name\n",
    "def return_columns(df, substring):\n",
    "    '''\n",
    "    This function returns the columns with a substring in the column name\n",
    "    \n",
    "    :param df:\n",
    "    :type df: pandas dataframe\n",
    "    \n",
    "    :param substring:\n",
    "    :type substring: string\n",
    "    '''\n",
    "    return df.loc[:, df.columns.str.contains(substring)]\n",
    "\n",
    "labels = return_columns(df_train, 'LABELS')\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eb73573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the columns without a substring in the column name\n",
    "def return_columns_without(df, substring):\n",
    "    '''\n",
    "    This function returns the columns without a substring in the column name\n",
    "    \n",
    "    :param df:\n",
    "    :type df: pandas dataframe\n",
    "    \n",
    "    :param substring:\n",
    "    :type substring: string\n",
    "    '''\n",
    "    return df.loc[:, ~df.columns.str.contains(substring)]\n",
    "\n",
    "features = return_columns_without(df_train, 'LABELS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd3b233",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# assume X_train and X_test are numpy arrays with string features\u001b[39;00m\n\u001b[0;32m      4\u001b[0m encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m----> 5\u001b[0m encoder\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfeatures\u001b[49m)\n\u001b[0;32m      6\u001b[0m X_train_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mtransform(features\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#Create logistic regression model and fit it to the data\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# assume X_train and X_test are numpy arrays with string features\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(features)\n",
    "X_train_encoded = encoder.transform(features.values)\n",
    "\n",
    "#Create logistic regression model and fit it to the data\n",
    "def create_model(features, labels):\n",
    "    '''\n",
    "    This function creates a logistic regression model and fits it to the data\n",
    "    \n",
    "    :param df:\n",
    "    :type df: pandas dataframe\n",
    "    \n",
    "    :param labels:\n",
    "    :type labels: pandas dataframe\n",
    "    '''\n",
    "    #Create logistic regression model\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "    #Fit the model to the data\n",
    "    logreg.fit(features, labels.values)\n",
    "    \n",
    "    return logreg\n",
    "\n",
    "#Train the model\n",
    "logreg = create_model(X_train_encoded, labels)\n",
    "\n",
    "#Predict the labels for the dev set\n",
    "predictions = logreg.predict(df_dev)\n",
    "\n",
    "#Create a dataframe with the predictions\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "\n",
    "#Create a dataframe with the correct labels\n",
    "df_correct_labels = return_columns(df_dev, 'LABELS')\n",
    "\n",
    "#Calculate the accuracy\n",
    "accuracy = (df_predictions == df_correct_labels).mean().mean()\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc51995-c2f1-45ab-8eb9-f4f4c25a0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "0b17a8072d1e4e10a3ac8e77e90feac1440cd12f9b0f4265949d4145395987cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

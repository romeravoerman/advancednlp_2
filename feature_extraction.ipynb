{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b62ae826-e6c6-40b8-be35-cc86ff999ec2",
   "metadata": {},
   "source": [
    "# Advanced NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012f747f-7a72-4a7a-a16b-5107aca519ec",
   "metadata": {},
   "source": [
    "*Notebook for Assignment 1 of Advanced NLP - Group 2 by Simone Colombo, Sophie van Duin, Iris Lau & Romera Voerman*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5341d-b652-4a86-8ac1-4afa323a321c",
   "metadata": {},
   "source": [
    "This notebook includes code that extracts the features proposed in part b) of the Syntax section. This includes: \n",
    "* The full constituent starting from a head word\n",
    "* A feature including the head of a target word\n",
    "* A feature including the dependent(s) of target word\n",
    "* A feature based on dependency relations (e.g. paths, relation to head, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e003cb9f-f2ab-40e4-9801-bf7a524ccf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc13475a-6aaf-4535-b8eb-f55abc68a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"As the sun set behind the mountains and the sky turned shades of orange and pink, Mary and Tom walked hand in hand along the deserted beach, listening to the sound of the waves crashing against the shore.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfd039b-9a31-4c9c-b766-245f61909790",
   "metadata": {},
   "source": [
    "#### Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb20d0ec-79e0-4d6a-9f8b-cf6602b0c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22838f4-f02e-44ba-8cf4-8dc15626e60e",
   "metadata": {},
   "source": [
    "Create dataframe of the tokenized sentence to add the extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c238f037-e7ed-487f-a7ec-5fc00bae72b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tokens, columns=['token'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbd2d2-0f4d-408e-968c-c0d78c1c2f93",
   "metadata": {},
   "source": [
    "#### Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b4d765-9083-4a7c-9585-dead0ec2fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# lemmatize each word in the sentence\n",
    "lemmatized_words = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "df['lemma'] = lemmatized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f690c-52c5-462f-8980-978ef4e56405",
   "metadata": {},
   "source": [
    "#### Part-of-Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b64bbf-f820-4c92-9f00-998c6a9f4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform part-of-speech tagging\n",
    "pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "df['pos'] = pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fd558-064a-495e-b7f3-4fde5991f66f",
   "metadata": {},
   "source": [
    "#### Dependency labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba85fa2-815a-47f9-a5b0-18948d0c80c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# perform dependency parsing\n",
    "doc = nlp(sentence)\n",
    "dep_labels = [token.dep_ for token in doc]\n",
    "\n",
    "df['dep_labels'] = dep_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90521c-25d7-4e0a-81f4-c53020d089a8",
   "metadata": {},
   "source": [
    "#### Preceding Part-of-Speech tags and dependency labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a422ff-b8b8-4a5c-bc0a-37d3b6a4cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preceding_pos = []\n",
    "preceding_dep = []\n",
    "for token in doc:\n",
    "    preceding_pos.append([t.pos_ for t in token.lefts])\n",
    "    preceding_dep.append([t.dep_ for t in token.lefts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9550b24-af19-4e61-a100-9ae142ea92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prec_pos'] = preceding_pos\n",
    "df['prec_dep'] = preceding_dep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c1896-cb0b-4e54-844d-3a17333fbc7e",
   "metadata": {},
   "source": [
    "#### Head of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6523398d-df35-4a4a-8c6d-dcdcdc9f9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_tags = [token.head for token in doc]\n",
    "df['head_tags'] = head_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f430f0-bfb3-4f41-8a21-c747c4683e99",
   "metadata": {},
   "source": [
    "#### Length of the path connecting each token with the ROOT of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "196e4282-59fe-4ad1-a82b-084e66fc3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for token in doc:\n",
    "    for child in token.children:\n",
    "        edges.append(('{0}'.format(token),\n",
    "                      '{0}'.format(child)))\n",
    "graph = nx.Graph(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb897f36-2a98-4782-ab8c-85bc98b560f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = df.loc[df.dep_labels == 'ROOT', 'token'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a189ec8b-851c-482a-a99a-ce5aad93d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = []\n",
    "\n",
    "for token in doc:\n",
    "    root_path.append(nx.shortest_path_length(graph, source=str(token), target=root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2fadf77-67d8-4dae-8269-d04c8534a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token-ROOT_path'] = root_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db7f799-360f-43bf-85ec-3396d705b2f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8387c04-8e0a-47d9-8a08-39d478276fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "children = []\n",
    "for token in doc:\n",
    "    token_children = [child.text for child in token.children]\n",
    "    children.append(token_children)\n",
    "\n",
    "df['children'] = children"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011255a-c51b-4f05-a666-b336af78868c",
   "metadata": {},
   "source": [
    "#### Word shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f7c7cfb-259c-4c03-81fb-a3e6991a0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_shapes = [token.shape_ for token in doc]\n",
    "df['word_shapes'] = word_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4093e022-41e2-4a97-a0b1-b3ad84145d30",
   "metadata": {},
   "source": [
    "## Full dataframe including extractedfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e787b7f-1038-40e9-8069-95d0365f28d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>dep_labels</th>\n",
       "      <th>prec_pos</th>\n",
       "      <th>prec_dep</th>\n",
       "      <th>head_tags</th>\n",
       "      <th>token-ROOT_path</th>\n",
       "      <th>children</th>\n",
       "      <th>word_shapes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As</td>\n",
       "      <td>As</td>\n",
       "      <td>(As, IN)</td>\n",
       "      <td>mark</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>set</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>Xx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>det</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>sun</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sun</td>\n",
       "      <td>sun</td>\n",
       "      <td>(sun, NN)</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>[DET]</td>\n",
       "      <td>[det]</td>\n",
       "      <td>set</td>\n",
       "      <td>2</td>\n",
       "      <td>[the]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set</td>\n",
       "      <td>set</td>\n",
       "      <td>(set, VBN)</td>\n",
       "      <td>advcl</td>\n",
       "      <td>[SCONJ, NOUN]</td>\n",
       "      <td>[mark, nsubj]</td>\n",
       "      <td>walked</td>\n",
       "      <td>1</td>\n",
       "      <td>[As, sun, behind, and, turned]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>behind</td>\n",
       "      <td>behind</td>\n",
       "      <td>(behind, IN)</td>\n",
       "      <td>prep</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>set</td>\n",
       "      <td>2</td>\n",
       "      <td>[mountains]</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>det</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>mountains</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mountains</td>\n",
       "      <td>mountain</td>\n",
       "      <td>(mountains, NNS)</td>\n",
       "      <td>pobj</td>\n",
       "      <td>[DET]</td>\n",
       "      <td>[det]</td>\n",
       "      <td>behind</td>\n",
       "      <td>3</td>\n",
       "      <td>[the]</td>\n",
       "      <td>xxxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>(and, CC)</td>\n",
       "      <td>cc</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>set</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>det</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>sky</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sky</td>\n",
       "      <td>sky</td>\n",
       "      <td>(sky, NN)</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>[DET]</td>\n",
       "      <td>[det]</td>\n",
       "      <td>turned</td>\n",
       "      <td>3</td>\n",
       "      <td>[the]</td>\n",
       "      <td>xxx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token     lemma               pos dep_labels       prec_pos  \\\n",
       "0         As        As          (As, IN)       mark             []   \n",
       "1        the       the         (the, DT)        det             []   \n",
       "2        sun       sun         (sun, NN)      nsubj          [DET]   \n",
       "3        set       set        (set, VBN)      advcl  [SCONJ, NOUN]   \n",
       "4     behind    behind      (behind, IN)       prep             []   \n",
       "5        the       the         (the, DT)        det             []   \n",
       "6  mountains  mountain  (mountains, NNS)       pobj          [DET]   \n",
       "7        and       and         (and, CC)         cc             []   \n",
       "8        the       the         (the, DT)        det             []   \n",
       "9        sky       sky         (sky, NN)      nsubj          [DET]   \n",
       "\n",
       "        prec_dep  head_tags  token-ROOT_path                        children  \\\n",
       "0             []        set                2                              []   \n",
       "1             []        sun                3                              []   \n",
       "2          [det]        set                2                           [the]   \n",
       "3  [mark, nsubj]     walked                1  [As, sun, behind, and, turned]   \n",
       "4             []        set                2                     [mountains]   \n",
       "5             []  mountains                3                              []   \n",
       "6          [det]     behind                3                           [the]   \n",
       "7             []        set                2                              []   \n",
       "8             []        sky                3                              []   \n",
       "9          [det]     turned                3                           [the]   \n",
       "\n",
       "  word_shapes  \n",
       "0          Xx  \n",
       "1         xxx  \n",
       "2         xxx  \n",
       "3         xxx  \n",
       "4        xxxx  \n",
       "5         xxx  \n",
       "6        xxxx  \n",
       "7         xxx  \n",
       "8         xxx  \n",
       "9         xxx  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fd4bf-14b2-4d35-94b9-50cbc806727d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
